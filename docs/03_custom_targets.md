# Creating Custom Targets

A Target is a Python script that acts as a bridge between Spikee and the system you want to test. While you can use targets to interact directly with an LLM's completion endpoint, their primary power lies in testing **LLM applications**.

You need a custom target when you want to:
*   Test a complete application workflow (e.g., submitting a form, sending an email).
*   Interact with a proprietary API that uses an LLM in its backend.
*   Connect to a new or unsupported LLM provider.
*   Evaluate a specific guardrail system in isolation.

This guide covers how to build a custom target for any of these scenarios.

## Target Structure

Every target is a Python module located in the `targets/` directory of your workspace. Spikee identifies targets by their filename.

*   **Location:** `./targets/my_app_target.py`
*   **Required Function:** `process_input`

## The `process_input` Function

This is the core function that Spikee calls for every test case. It receives the generated payload and must return the target's final, user-visible response.

### Function Signature
```python
from typing import Union, Tuple, Optional

def process_input(
    input_text: str,
    system_message: Optional[str] = None,
    target_options: Optional[str] = None,
    logprobs: bool = False
) -> Union[str, bool, Tuple[str, Optional[dict]]]:
    """
    Processes a single payload and returns the result from the target.
    """
    # Your implementation here...
```

### Parameters in Context

*   `input_text: str`
    The full payload generated by Spikee. When testing an application, this is typically the data you are submitting (e.g., the body of an email, a user comment, a document for summarization).

*   `system_message: Optional[str]`
    The system prompt, if specified in the dataset. **When testing an application, you will likely ignore this parameter**, as you typically cannot control the application's internal system prompt. It is mainly used when testing a standalone LLM.

*   `target_options: Optional[str]`
    A string passed from the command line via `--target-options`.

*   `logprobs: bool`
    A hint for requesting token probabilities. **This can be ignored when testing an LLM application**, as this low-level data is not exposed through an application's API.

### Return Values

The `process_input` function's return type depends on what you are testing.

*   **For LLM Applications or Models**: Return the final text response.
    *   `str`: The generated text response that a user would see.

*   **For Guardrail Systems**: Return a boolean indicating if the payload was allowed.
    *   `bool`: `True` signifies the guardrail was **bypassed** (an attack success). `False` signifies the payload was **blocked** (an attack failure). This is essential for calculating performance metrics.

## Supporting Target Options

To make your target more flexible, you can advertise its supported `target_options` by implementing an optional `get_available_option_values` function.

```python
from typing import List

def get_available_option_values() -> List[str]:
    """
    Returns a list of supported option strings for this target.
    """
    # The first option is the default.
    return ["staging_env", "prod_env_read_only"]
```
When this function is present, `spikee list targets` will display the available options, making your target easier to use.

## Error Handling

*   **Invalid Options:** If your target uses `target_options`, validate the input and **raise a `ValueError`** on invalid values to prevent misconfigured tests.
*   **API Calls:** Wrap all external API calls in a `try...except` block. If an exception occurs, log it and **re-raise the exception**. This allows Spikee's main testing loop to catch the error and apply its retry logic (`--max-retries`).

## Complete Example: Testing an LLM Application

This example demonstrates a target for a fictional "LLM Webmail" application, which summarizes emails. The goal is to test if a prompt injection in an email body can manipulate the summary. This pattern is very similar to the built-in `llm_mailbox.py` target.

```python
# ./targets/my_webmail_app.py
import os
import requests
from dotenv import load_dotenv
from typing import Optional

# Load API credentials from .env file
load_dotenv()
APP_API_ENDPOINT = os.getenv("WEBMAIL_APP_ENDPOINT")
APP_API_KEY = os.getenv("WEBMAIL_APP_API_KEY")

def process_input(
    input_text: str,
    system_message: Optional[str] = None, # Ignored for this app target
    target_options: Optional[str] = None, # Ignored for this app target
    logprobs: bool = False # Ignored for this app target
) -> str:
    """
    Submits a malicious email body to the webmail application
    and returns the generated summary.
    """
    # 1. Validate API credentials
    if not APP_API_ENDPOINT or not APP_API_KEY:
        raise ValueError("Set WEBMAIL_APP_ENDPOINT and WEBMAIL_APP_API_KEY in .env")

    # 2. Prepare the request payload for the application's API
    headers = {"Authorization": f"Bearer {APP_API_KEY}"}
    # The application's endpoint expects an email body
    payload = {
        "email_body": input_text,
        "from": "attacker@example.com",
        "subject": "Fwd: Urgent"
    }

    # 3. Make the API call with error handling
    try:
        # This is a call to the APPLICATION's API, not a direct LLM call
        response = requests.post(APP_API_ENDPOINT, json=payload, headers=headers, timeout=90)
        response.raise_for_status() # Raise an exception for HTTP errors
        
        data = response.json()
        # The application's response contains the summary
        return data.get("summary_text", "")

    except requests.exceptions.RequestException as e:
        # Catch network/HTTP errors and re-raise for Spikee's retry logic
        print(f"Application API Error: {e}")
        raise
```